{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "csefcXAcRlkM"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
        "img_rows, img_cols = 224, 224 "
      ],
      "metadata": {
        "id": "0Dcu9zsCSMsf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZaiFN5FTGqd",
        "outputId": "829311a8-7f8c-4eb3-a6e8-dd6ba068ea59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/DL/Hackathon_FakeVsReal/train'\n",
        "validation_data_dir = '/content/drive/My Drive/DL/Hackathon_FakeVsReal/test'\n",
        "\n",
        "# Let's use some data augmentaiton \n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=45,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "metadata": {
        "id": "6H51saGCSfQl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   validation_split=0.25) \n",
        "# set our batch size (typically on most mid tier systems we'll use 16-32)\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        subset=\"training\",\n",
        "        seed=42,\n",
        "        shuffle=True,\n",
        "        class_mode='binary')\n",
        " \n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        subset=\"validation\",\n",
        "        seed=42,\n",
        "        shuffle=True,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_rkWcRQSouV",
        "outputId": "2896eaca-7e30-482a-8164-126ad6c90253"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1282 images belonging to 2 classes.\n",
            "Found 427 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data_dir = '/content/drive/My Drive/DL/Hackathon_FakeVsReal/test/'\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXiplOwoTRyF",
        "outputId": "aff6b954-3efe-4c77-bbe0-268a569d1ed3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 332 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnet = MobileNetV2(include_top = False, weights = \"imagenet\" ,input_shape=(96,96,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGBdkek5Tm_9",
        "outputId": "8e577217-d2d3-4356-b124-d061201117b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model_mnet = Sequential([mnet,\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    Dense(512, activation = \"relu\"),\n",
        "                    BatchNormalization(),\n",
        "                    Dropout(0.3),\n",
        "                    Dense(128, activation = \"relu\"),\n",
        "                    Dropout(0.1),\n",
        "                    # Dense(32, activation = \"relu\"),\n",
        "                    # Dropout(0.3),\n",
        "                    Dense(2, activation = \"softmax\")])\n",
        "\n",
        "model_mnet.layers[0].trainable = False\n",
        "\n",
        "model_mnet.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
        "\n",
        "model_mnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qkN5JUXT-3c",
        "outputId": "5d419bd9-6ead-4222-df1e-389a97b210ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_96 (Functi  (None, 3, 3, 1280)       2257984   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               655872    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,981,826\n",
            "Trainable params: 722,818\n",
            "Non-trainable params: 2,259,008\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch <= 2:\n",
        "        return 0.001\n",
        "    elif epoch > 2 and epoch <= 15:\n",
        "        return 0.0001 \n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "lr_callbacks = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "2BQ2tKD8U6Sv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model_mnet.fit_generator(train_generator,\n",
        "                    epochs=20,\n",
        "                    callbacks=[lr_callbacks],\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rudgViBVGoD",
        "outputId": "f3561aba-bc88-4dea-a3db-9ac5e810e9a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "41/41 [==============================] - 440s 11s/step - loss: 0.8629 - accuracy: 0.5741 - val_loss: 0.7095 - val_accuracy: 0.5504 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.7355 - accuracy: 0.6373 - val_loss: 0.7883 - val_accuracy: 0.5597 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.6601 - accuracy: 0.6529 - val_loss: 0.8069 - val_accuracy: 0.5808 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.6232 - accuracy: 0.6958 - val_loss: 0.7079 - val_accuracy: 0.6183 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5827 - accuracy: 0.6958 - val_loss: 0.7542 - val_accuracy: 0.5738 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5565 - accuracy: 0.7246 - val_loss: 0.7204 - val_accuracy: 0.5948 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5596 - accuracy: 0.7090 - val_loss: 0.7378 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5404 - accuracy: 0.7418 - val_loss: 0.7609 - val_accuracy: 0.5691 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5609 - accuracy: 0.7122 - val_loss: 0.7495 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "41/41 [==============================] - 51s 1s/step - loss: 0.5529 - accuracy: 0.7223 - val_loss: 0.7677 - val_accuracy: 0.5902 - lr: 1.0000e-04\n",
            "Epoch 11/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5423 - accuracy: 0.7293 - val_loss: 0.7299 - val_accuracy: 0.5831 - lr: 1.0000e-04\n",
            "Epoch 12/20\n",
            "41/41 [==============================] - 49s 1s/step - loss: 0.5298 - accuracy: 0.7363 - val_loss: 0.7679 - val_accuracy: 0.5972 - lr: 1.0000e-04\n",
            "Epoch 13/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5249 - accuracy: 0.7262 - val_loss: 0.7174 - val_accuracy: 0.6323 - lr: 1.0000e-04\n",
            "Epoch 14/20\n",
            "41/41 [==============================] - 49s 1s/step - loss: 0.5121 - accuracy: 0.7480 - val_loss: 0.7564 - val_accuracy: 0.5527 - lr: 1.0000e-04\n",
            "Epoch 15/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5347 - accuracy: 0.7418 - val_loss: 0.7603 - val_accuracy: 0.6136 - lr: 1.0000e-04\n",
            "Epoch 16/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5352 - accuracy: 0.7465 - val_loss: 0.7261 - val_accuracy: 0.5855 - lr: 1.0000e-04\n",
            "Epoch 17/20\n",
            "41/41 [==============================] - 49s 1s/step - loss: 0.5328 - accuracy: 0.7278 - val_loss: 0.7273 - val_accuracy: 0.5948 - lr: 1.0000e-05\n",
            "Epoch 18/20\n",
            "41/41 [==============================] - 49s 1s/step - loss: 0.5195 - accuracy: 0.7285 - val_loss: 0.7454 - val_accuracy: 0.5761 - lr: 1.0000e-05\n",
            "Epoch 19/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5266 - accuracy: 0.7340 - val_loss: 0.7415 - val_accuracy: 0.5644 - lr: 1.0000e-05\n",
            "Epoch 20/20\n",
            "41/41 [==============================] - 50s 1s/step - loss: 0.5247 - accuracy: 0.7379 - val_loss: 0.7293 - val_accuracy: 0.6066 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict1 = model_mnet.predict(test_generator)"
      ],
      "metadata": {
        "id": "bnB3mQVsfS6G"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMQVHaBhfavX",
        "outputId": "d98f676c-f4a9-4701-a97b-27ad34a96526"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5156464 , 0.48435363],\n",
              "       [0.27035445, 0.72964555],\n",
              "       [0.17382741, 0.8261726 ],\n",
              "       [0.7826337 , 0.21736626],\n",
              "       [0.35038874, 0.64961123],\n",
              "       [0.5449114 , 0.45508865],\n",
              "       [0.09427951, 0.9057205 ],\n",
              "       [0.66886294, 0.33113706],\n",
              "       [0.80154824, 0.19845176],\n",
              "       [0.38452443, 0.61547554],\n",
              "       [0.19764733, 0.8023527 ],\n",
              "       [0.82556075, 0.17443922],\n",
              "       [0.9016651 , 0.09833486],\n",
              "       [0.3027129 , 0.6972871 ],\n",
              "       [0.30390045, 0.6960996 ],\n",
              "       [0.7684464 , 0.23155358],\n",
              "       [0.8137579 , 0.18624209],\n",
              "       [0.4721168 , 0.52788323],\n",
              "       [0.7705013 , 0.22949874],\n",
              "       [0.45023683, 0.5497632 ],\n",
              "       [0.91220856, 0.08779137],\n",
              "       [0.12290932, 0.87709063],\n",
              "       [0.80275905, 0.197241  ],\n",
              "       [0.6841434 , 0.31585655],\n",
              "       [0.04052729, 0.95947266],\n",
              "       [0.220408  , 0.779592  ],\n",
              "       [0.67338526, 0.3266147 ],\n",
              "       [0.66140085, 0.33859915],\n",
              "       [0.83896625, 0.16103378],\n",
              "       [0.46797752, 0.5320225 ],\n",
              "       [0.15295827, 0.8470417 ],\n",
              "       [0.19398609, 0.80601394],\n",
              "       [0.62144023, 0.3785598 ],\n",
              "       [0.53121424, 0.46878573],\n",
              "       [0.35782477, 0.64217526],\n",
              "       [0.1864601 , 0.8135399 ],\n",
              "       [0.322217  , 0.67778295],\n",
              "       [0.6297338 , 0.3702662 ],\n",
              "       [0.08220913, 0.9177909 ],\n",
              "       [0.33158222, 0.66841775],\n",
              "       [0.52973324, 0.4702667 ],\n",
              "       [0.6235293 , 0.3764707 ],\n",
              "       [0.16486877, 0.8351313 ],\n",
              "       [0.62397087, 0.3760291 ],\n",
              "       [0.76986194, 0.23013808],\n",
              "       [0.3727714 , 0.6272286 ],\n",
              "       [0.5292133 , 0.4707867 ],\n",
              "       [0.6073482 , 0.3926519 ],\n",
              "       [0.6477945 , 0.35220557],\n",
              "       [0.5874471 , 0.41255298],\n",
              "       [0.9523336 , 0.04766639],\n",
              "       [0.93867624, 0.06132372],\n",
              "       [0.5587463 , 0.44125372],\n",
              "       [0.6427831 , 0.35721692],\n",
              "       [0.8551163 , 0.14488368],\n",
              "       [0.5540181 , 0.44598198],\n",
              "       [0.54519415, 0.45480585],\n",
              "       [0.8072269 , 0.19277318],\n",
              "       [0.774719  , 0.22528102],\n",
              "       [0.58180034, 0.41819966],\n",
              "       [0.30603585, 0.6939641 ],\n",
              "       [0.39128703, 0.608713  ],\n",
              "       [0.9055338 , 0.09446615],\n",
              "       [0.2654152 , 0.7345848 ],\n",
              "       [0.40322047, 0.5967795 ],\n",
              "       [0.36300105, 0.636999  ],\n",
              "       [0.57788163, 0.42211846],\n",
              "       [0.11149924, 0.8885008 ],\n",
              "       [0.30160797, 0.69839203],\n",
              "       [0.17949301, 0.82050705],\n",
              "       [0.6623598 , 0.33764014],\n",
              "       [0.8338759 , 0.16612412],\n",
              "       [0.9926796 , 0.0073204 ],\n",
              "       [0.8939256 , 0.10607439],\n",
              "       [0.2534774 , 0.7465226 ],\n",
              "       [0.36487013, 0.6351299 ],\n",
              "       [0.71395546, 0.28604454],\n",
              "       [0.00844596, 0.9915541 ],\n",
              "       [0.4680019 , 0.53199804],\n",
              "       [0.8419991 , 0.15800086],\n",
              "       [0.3281132 , 0.6718868 ],\n",
              "       [0.7399686 , 0.26003146],\n",
              "       [0.761908  , 0.238092  ],\n",
              "       [0.9588526 , 0.04114741],\n",
              "       [0.8946139 , 0.10538605],\n",
              "       [0.20105682, 0.7989432 ],\n",
              "       [0.38204786, 0.61795205],\n",
              "       [0.912889  , 0.087111  ],\n",
              "       [0.73150784, 0.26849213],\n",
              "       [0.3447478 , 0.6552522 ],\n",
              "       [0.25645843, 0.7435416 ],\n",
              "       [0.94711393, 0.05288605],\n",
              "       [0.5024192 , 0.49758077],\n",
              "       [0.56425214, 0.4357478 ],\n",
              "       [0.72616506, 0.27383488],\n",
              "       [0.95476085, 0.04523915],\n",
              "       [0.47842112, 0.5215789 ],\n",
              "       [0.05664944, 0.94335055],\n",
              "       [0.31436324, 0.68563676],\n",
              "       [0.65453386, 0.34546614],\n",
              "       [0.85373604, 0.146264  ],\n",
              "       [0.6372968 , 0.36270317],\n",
              "       [0.72645915, 0.27354094],\n",
              "       [0.9426812 , 0.05731878],\n",
              "       [0.43267396, 0.567326  ],\n",
              "       [0.93563557, 0.06436442],\n",
              "       [0.66079915, 0.33920085],\n",
              "       [0.8716694 , 0.12833056],\n",
              "       [0.13834539, 0.8616546 ],\n",
              "       [0.6164942 , 0.38350585],\n",
              "       [0.711338  , 0.28866202],\n",
              "       [0.96466297, 0.035337  ],\n",
              "       [0.5599983 , 0.44000182],\n",
              "       [0.8674753 , 0.13252479],\n",
              "       [0.7986718 , 0.20132825],\n",
              "       [0.91222405, 0.087776  ],\n",
              "       [0.5905948 , 0.40940523],\n",
              "       [0.79491574, 0.20508426],\n",
              "       [0.55172837, 0.44827163],\n",
              "       [0.5317447 , 0.4682553 ],\n",
              "       [0.6017971 , 0.3982029 ],\n",
              "       [0.7584875 , 0.24151246],\n",
              "       [0.3052144 , 0.6947856 ],\n",
              "       [0.97644216, 0.02355785],\n",
              "       [0.55756176, 0.44243822],\n",
              "       [0.79359525, 0.20640475],\n",
              "       [0.97086304, 0.02913703],\n",
              "       [0.8894641 , 0.11053587],\n",
              "       [0.20172241, 0.79827756],\n",
              "       [0.79898125, 0.20101878],\n",
              "       [0.7989318 , 0.20106824],\n",
              "       [0.9515645 , 0.04843558],\n",
              "       [0.8463512 , 0.15364887],\n",
              "       [0.82137865, 0.17862134],\n",
              "       [0.9743741 , 0.02562587],\n",
              "       [0.1756399 , 0.82436013],\n",
              "       [0.7908317 , 0.20916826],\n",
              "       [0.58741045, 0.41258955],\n",
              "       [0.20040712, 0.79959285],\n",
              "       [0.2212715 , 0.7787285 ],\n",
              "       [0.55485207, 0.44514793],\n",
              "       [0.77645415, 0.22354582],\n",
              "       [0.19991551, 0.8000845 ],\n",
              "       [0.31063592, 0.6893641 ],\n",
              "       [0.82959044, 0.17040958],\n",
              "       [0.267387  , 0.732613  ],\n",
              "       [0.33869898, 0.66130096],\n",
              "       [0.49604848, 0.5039515 ],\n",
              "       [0.8498152 , 0.15018483],\n",
              "       [0.74933845, 0.25066152],\n",
              "       [0.0975192 , 0.90248084],\n",
              "       [0.6119517 , 0.3880483 ],\n",
              "       [0.79175025, 0.20824972],\n",
              "       [0.13047178, 0.8695282 ],\n",
              "       [0.10541091, 0.89458907],\n",
              "       [0.2468273 , 0.75317264],\n",
              "       [0.5653774 , 0.4346225 ],\n",
              "       [0.2642907 , 0.73570937],\n",
              "       [0.9245066 , 0.07549335],\n",
              "       [0.12390578, 0.87609416],\n",
              "       [0.5436065 , 0.45639348],\n",
              "       [0.54543316, 0.45456684],\n",
              "       [0.16561371, 0.83438635],\n",
              "       [0.01746225, 0.9825378 ],\n",
              "       [0.05665174, 0.9433482 ],\n",
              "       [0.63973266, 0.36026743],\n",
              "       [0.40371987, 0.5962801 ],\n",
              "       [0.1912612 , 0.80873877],\n",
              "       [0.09689517, 0.9031048 ],\n",
              "       [0.1395349 , 0.8604651 ],\n",
              "       [0.8254161 , 0.17458391],\n",
              "       [0.64336324, 0.35663676],\n",
              "       [0.105208  , 0.894792  ],\n",
              "       [0.7921604 , 0.20783956],\n",
              "       [0.3743882 , 0.6256118 ],\n",
              "       [0.7945858 , 0.20541418],\n",
              "       [0.5626199 , 0.4373801 ],\n",
              "       [0.67968583, 0.32031417],\n",
              "       [0.914952  , 0.08504805],\n",
              "       [0.8193612 , 0.18063873],\n",
              "       [0.8069829 , 0.19301714],\n",
              "       [0.2126117 , 0.78738827],\n",
              "       [0.8730666 , 0.12693338],\n",
              "       [0.60327286, 0.39672717],\n",
              "       [0.02630309, 0.9736969 ],\n",
              "       [0.3764512 , 0.6235488 ],\n",
              "       [0.07324   , 0.92676   ],\n",
              "       [0.35313573, 0.64686424],\n",
              "       [0.09785686, 0.9021432 ],\n",
              "       [0.6286201 , 0.37137997],\n",
              "       [0.51175755, 0.48824248],\n",
              "       [0.7055666 , 0.29443341],\n",
              "       [0.45645055, 0.5435494 ],\n",
              "       [0.4697119 , 0.5302881 ],\n",
              "       [0.54857683, 0.45142308],\n",
              "       [0.6747019 , 0.32529813],\n",
              "       [0.11646828, 0.88353175],\n",
              "       [0.69661736, 0.30338258],\n",
              "       [0.54340684, 0.45659313],\n",
              "       [0.3404312 , 0.6595688 ],\n",
              "       [0.14443886, 0.8555612 ],\n",
              "       [0.17971404, 0.8202859 ],\n",
              "       [0.28100178, 0.71899825],\n",
              "       [0.8527417 , 0.14725828],\n",
              "       [0.13986282, 0.86013716],\n",
              "       [0.66982096, 0.330179  ],\n",
              "       [0.15734196, 0.84265804],\n",
              "       [0.06416529, 0.9358347 ],\n",
              "       [0.33525822, 0.6647418 ],\n",
              "       [0.3107721 , 0.6892279 ],\n",
              "       [0.43261102, 0.567389  ],\n",
              "       [0.920762  , 0.07923794],\n",
              "       [0.8951161 , 0.10488389],\n",
              "       [0.841161  , 0.15883899],\n",
              "       [0.70436794, 0.2956321 ],\n",
              "       [0.1869116 , 0.8130884 ],\n",
              "       [0.3451525 , 0.6548475 ],\n",
              "       [0.17620903, 0.82379097],\n",
              "       [0.71501595, 0.28498405],\n",
              "       [0.66367483, 0.33632523],\n",
              "       [0.12942678, 0.8705733 ],\n",
              "       [0.36847916, 0.6315208 ],\n",
              "       [0.5604347 , 0.43956533],\n",
              "       [0.03527988, 0.96472013],\n",
              "       [0.6314513 , 0.36854866],\n",
              "       [0.53559023, 0.46440977],\n",
              "       [0.11119944, 0.88880056],\n",
              "       [0.5260704 , 0.47392964],\n",
              "       [0.32212037, 0.6778796 ],\n",
              "       [0.08789593, 0.912104  ],\n",
              "       [0.38194335, 0.6180567 ],\n",
              "       [0.18202688, 0.81797314],\n",
              "       [0.12203447, 0.87796557],\n",
              "       [0.77786756, 0.22213241],\n",
              "       [0.7796648 , 0.22033514],\n",
              "       [0.39925954, 0.60074043],\n",
              "       [0.4756936 , 0.5243064 ],\n",
              "       [0.7323468 , 0.26765323],\n",
              "       [0.5605284 , 0.43947157],\n",
              "       [0.35824868, 0.64175135],\n",
              "       [0.30008042, 0.6999196 ],\n",
              "       [0.17441933, 0.82558066],\n",
              "       [0.04448844, 0.95551157],\n",
              "       [0.22771873, 0.7722813 ],\n",
              "       [0.15037537, 0.84962463],\n",
              "       [0.9744081 , 0.02559196],\n",
              "       [0.5370901 , 0.46290982],\n",
              "       [0.91004133, 0.08995865],\n",
              "       [0.6250232 , 0.3749768 ],\n",
              "       [0.39138278, 0.60861725],\n",
              "       [0.48370853, 0.5162915 ],\n",
              "       [0.24569009, 0.7543099 ],\n",
              "       [0.61155385, 0.38844618],\n",
              "       [0.54712605, 0.45287398],\n",
              "       [0.06017956, 0.93982047],\n",
              "       [0.10750933, 0.8924906 ],\n",
              "       [0.9207041 , 0.07929585],\n",
              "       [0.5738152 , 0.42618477],\n",
              "       [0.8952952 , 0.10470478],\n",
              "       [0.11990241, 0.88009757],\n",
              "       [0.31926098, 0.680739  ],\n",
              "       [0.4578678 , 0.5421322 ],\n",
              "       [0.5929597 , 0.40704033],\n",
              "       [0.43829554, 0.56170446],\n",
              "       [0.04808333, 0.9519167 ],\n",
              "       [0.38553238, 0.61446756],\n",
              "       [0.4926771 , 0.5073229 ],\n",
              "       [0.76876974, 0.23123029],\n",
              "       [0.07795752, 0.9220425 ],\n",
              "       [0.69150627, 0.3084937 ],\n",
              "       [0.8830124 , 0.11698762],\n",
              "       [0.57644653, 0.4235534 ],\n",
              "       [0.87211245, 0.12788753],\n",
              "       [0.22426724, 0.77573276],\n",
              "       [0.43132564, 0.5686744 ],\n",
              "       [0.8988736 , 0.10112635],\n",
              "       [0.7918855 , 0.20811452],\n",
              "       [0.10820865, 0.8917914 ],\n",
              "       [0.8458584 , 0.15414156],\n",
              "       [0.952776  , 0.04722399],\n",
              "       [0.38518554, 0.6148144 ],\n",
              "       [0.5628966 , 0.43710342],\n",
              "       [0.55591816, 0.4440819 ],\n",
              "       [0.5049131 , 0.49508694],\n",
              "       [0.91137826, 0.0886218 ],\n",
              "       [0.7306172 , 0.26938275],\n",
              "       [0.5146494 , 0.48535064],\n",
              "       [0.99179924, 0.00820081],\n",
              "       [0.25732955, 0.7426704 ],\n",
              "       [0.72995794, 0.27004203],\n",
              "       [0.5749125 , 0.42508745],\n",
              "       [0.74374014, 0.25625983],\n",
              "       [0.68642205, 0.31357798],\n",
              "       [0.8184919 , 0.18150806],\n",
              "       [0.7730888 , 0.22691117],\n",
              "       [0.66278684, 0.33721316],\n",
              "       [0.67992216, 0.32007787],\n",
              "       [0.6162843 , 0.38371575],\n",
              "       [0.8094511 , 0.19054893],\n",
              "       [0.34955853, 0.65044147],\n",
              "       [0.27363226, 0.7263678 ],\n",
              "       [0.02811084, 0.9718892 ],\n",
              "       [0.80435693, 0.19564304],\n",
              "       [0.52472353, 0.47527653],\n",
              "       [0.7159881 , 0.28401187],\n",
              "       [0.14328253, 0.85671747],\n",
              "       [0.7161842 , 0.28381586],\n",
              "       [0.7262824 , 0.27371755],\n",
              "       [0.81936216, 0.18063784],\n",
              "       [0.46260184, 0.5373981 ],\n",
              "       [0.26459193, 0.73540807],\n",
              "       [0.32663035, 0.67336965],\n",
              "       [0.6181962 , 0.38180387],\n",
              "       [0.5079849 , 0.49201512],\n",
              "       [0.71504945, 0.28495064],\n",
              "       [0.86593103, 0.13406903],\n",
              "       [0.27152053, 0.72847956],\n",
              "       [0.9945639 , 0.00543615],\n",
              "       [0.91647494, 0.08352499],\n",
              "       [0.24678092, 0.7532191 ],\n",
              "       [0.73200613, 0.26799387],\n",
              "       [0.09167019, 0.9083298 ],\n",
              "       [0.8306305 , 0.16936947],\n",
              "       [0.51582646, 0.4841736 ],\n",
              "       [0.91882825, 0.08117168],\n",
              "       [0.8681767 , 0.13182332],\n",
              "       [0.90183604, 0.09816398],\n",
              "       [0.8689189 , 0.13108113],\n",
              "       [0.89707273, 0.10292724],\n",
              "       [0.29777628, 0.70222366],\n",
              "       [0.8727454 , 0.12725462],\n",
              "       [0.5339628 , 0.46603718]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels1 = []\n",
        "for i in range(len(test_predict1)):\n",
        "  if test_predict1[i][0] <= 0.5 :\n",
        "    labels1.append(0)\n",
        "  else:\n",
        "    labels1.append(1)"
      ],
      "metadata": {
        "id": "5VrV8zDBf96V"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv5wfR1TgHh2",
        "outputId": "412996f7-29e2-44f0-e476-ea69b4bec6d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSfLMoLhine-",
        "outputId": "c76f0fa7-80c0-4519-b0df-ce26d272ef60"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.output[-1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VzeiDRNipKM",
        "outputId": "519f42e2-5b1e-4635-d580-d8877f306872"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(7, 7, 512) dtype=float32 (created by layer 'tf.__operators__.getitem')>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# for layer in vgg16_model.layers[:-1]:\n",
        "#     model.add(layer)\n",
        "\n",
        "# for layer in model.layers:\n",
        "#     layer.trainable = False\n",
        "    \n",
        "# model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "model_vgg = Sequential([vgg16_model,\n",
        "                    Flatten(),\n",
        "#                     GlobalAveragePooling2D(),\n",
        "#                     Dense(512, activation = \"relu\"),\n",
        "#                     BatchNormalization(),\n",
        "#                     Dropout(0.3),\n",
        "#                     Dense(128, activation = \"relu\"),\n",
        "#                     Dropout(0.1),\n",
        "#                     # Dense(32, activation = \"relu\"),\n",
        "#                     # Dropout(0.3),\n",
        "                    Dense(2, activation = \"softmax\")])\n",
        "\n",
        "model_vgg.layers[0].trainable = False\n",
        "\n",
        "model_vgg.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
        "\n",
        "model_vgg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyFd6r35ipNV",
        "outputId": "058d3b82-da8a-4a6c-aee9-adcbd7fc3b1a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist =  model_vgg.fit_generator(train_generator,\n",
        "                    epochs=20,\n",
        "                    callbacks=[lr_callbacks],\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZKZ5fncipQk",
        "outputId": "979d2ef5-16b4-4fcc-e325-d1be6986e821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "41/41 [==============================] - 605s 15s/step - loss: 1.1723 - accuracy: 0.5468 - val_loss: 0.7848 - val_accuracy: 0.5972 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "41/41 [==============================] - 656s 16s/step - loss: 0.7526 - accuracy: 0.5928 - val_loss: 0.8882 - val_accuracy: 0.5808 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "41/41 [==============================] - 657s 16s/step - loss: 0.8079 - accuracy: 0.6030 - val_loss: 0.8070 - val_accuracy: 0.5785 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "41/41 [==============================] - 606s 15s/step - loss: 0.6446 - accuracy: 0.6755 - val_loss: 0.7416 - val_accuracy: 0.6112 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "41/41 [==============================] - 657s 16s/step - loss: 0.6068 - accuracy: 0.7051 - val_loss: 0.7794 - val_accuracy: 0.5925 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "41/41 [==============================] - 657s 16s/step - loss: 0.5709 - accuracy: 0.7114 - val_loss: 0.7439 - val_accuracy: 0.5972 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "41/41 [==============================] - 656s 16s/step - loss: 0.5870 - accuracy: 0.6841 - val_loss: 0.7477 - val_accuracy: 0.6042 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "41/41 [==============================] - 662s 16s/step - loss: 0.5892 - accuracy: 0.7106 - val_loss: 0.7694 - val_accuracy: 0.5878 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "41/41 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.7262 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UThushRwipTb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}